library(rminer)
library(randomForest)
library(rpart.plot)
library(caTools)
library(caret)
library(mltools)
library(ade4)
library(data.table)
library(nnet)
base=read.csv("C:/Users/andre/Desktop/OneDrive - Universidade do Minho/DataMining/tb/student-mat.csv", header = TRUE, sep = ";")
#------------------------DATA UNDERSTANDING-------------------------------------
print(base)
is.na(base) #ver missing values
sapply(base, function(x) sum(is.na(x))) #ver missing values resumido
#ver se todos os valores estÃ£o dentro do esperado
summary(base)
#ver outliers
boxplot(base$age, col = "blue") #idade 1 outlier (remover 22anos)
boxplot(base$absences, col = "blue") #nao se retirar
boxplot(base$G1, col = "blue") # 0outlier
boxplot(base$G2, col = "blue")# 1outlier (nao remover)
hist(base$G3, col = "blue", breaks = 20) #ver distribuicao
#Tornar atributos binarios em 0 e 1
base$school [base$school  == 'GP'] = 0
base$school [base$school  == 'MS'] = 1
base$sex[base$sex == 'F'] = 0
base$sex[base$sex == 'M'] = 1
base$address [base$address == 'U'] = 0
base$address [base$address  == 'R'] = 1
base$famsize [base$famsize == 'LE3'] = 0
base$famsize [base$famsize  == 'GT3'] = 1
base$Pstatus  [base$Pstatus == 'T'] = 0
base$Pstatus  [base$Pstatus  == 'A'] = 1
base$schoolsup [base$schoolsup == 'no'] = 0
base$schoolsup  [base$schoolsup  == 'yes'] = 1
base$famsup [base$famsup == 'no'] = 0
base$famsup  [base$famsup  == 'yes'] = 1
base$paid [base$paid == 'no'] = 0
base$paid  [base$paid  == 'yes'] = 1
base$activities [base$activities == 'no'] = 0
base$activities  [base$activities  == 'yes'] = 1
base$nursery [base$nursery == 'no'] = 0
base$nursery  [base$nursery  == 'yes'] = 1
base$higher [base$higher == 'no'] = 0
base$higher  [base$higher  == 'yes'] = 1
base$internet [base$internet == 'no'] = 0
base$internet  [base$internet  == 'yes'] = 1
base$romantic [base$romantic == 'no'] = 0
base$romantic  [base$romantic  == 'yes'] = 1
#base$school=as.numeric(base$school)
#base$address=as.numeric(base$address)
#base$famsize=as.numeric(base$famsize)
#base$Pstatus=as.numeric(base$Pstatus)
#base$schoolsup=as.numeric(base$schoolsup)
#base$activities=as.numeric(base$activities)
#base$sex=as.numeric(base$sex)
#base$famsup=as.numeric(base$famsup)
#base$nursery=as.numeric(base$nursery)
#base$higher=as.numeric(base$higher)
#base$internet=as.numeric(base$internet)
#base$romantic=as.numeric(base$romantic)
#base$paid=as.numeric(base$paid)
ohe_feats = c("Mjob","Fjob","reason","guardian")
dummies = dummyVars(~ Mjob + Fjob + reason + guardian , data = base)
df_all_ohe =  as.data.frame(predict(dummies, newdata = base))
df_all_combined = cbind(base[,-c(which(colnames(base) %in% ohe_feats))],df_all_ohe)
base = as.data.frame(df_all_combined)
#---------Definir-as-restantes-bases-de-dados-------------
base2=base
base_binary=base
base3=base
#Criacao de base de dados com 5 valores
#base2$G3=cut(base$G3,c(-1,10,12,14,16,21),c(0,1,2,3,4))
base2$G3=cut(base$G3,c(-1,10,12,14,16,21),c(5,4,3,2,1))
#Criacao de base binaria
base_binary$G3[base$G3 < 10] = 0
base_binary$G3[base$G3 >= 10] = 1
#-----------------------DATA PREPARATION----------------------------------------
#retirar outliers
base= base[base[, "age"] <22,]
summary(base$age) #verificando o maximo
base2= base2[base2[, "age"] <22,]
base_binary= base_binary[base_binary[, "age"] <22,]
#---------------------
### exploration of some rminer classification models:
#--http://math.furman.edu/~dcs/courses/math47/R/library/randomForest/html/varImpPlot.html---
#Ver a importancia de cada atributo
set.seed(4543)
#data(base)
mtcars.rf <- randomForest(G3 ~ ., data=base, ntree=2000, keep.forest=FALSE,importance=TRUE)
varImpPlot(mtcars.rf)
#Retirar as coluna de G1 e G2 que sao muito preditivas
#base$G2 = NULL
#base$G1= NULL
#base2$G2 = NULL
#base2$G1= NULL
#base_binary$G2 = NULL
#base_binary$G1= NULL
set.seed(4543)
#(base)
mtcars.rf <- randomForest(G3 ~ ., data=base, ntree=2000, keep.forest=FALSE,importance=TRUE)
varImpPlot(mtcars.rf)
#-------------divide-data-------------
dataset_divide=sample.split(base,SplitRatio=0.7)
df_train=base[dataset_divide==TRUE, ]
df_test=base[dataset_divide==FALSE, ]
#-------------Random-Forest-------------
inputs=1:32 # all except pass and five
g3=which(names(base)=="G3")
cat("output class:",class(base[,g3]),"\n")
rmath=base[,c(inputs,g3)] # for easy use
y=rmath$g3 # target
# mining for randomForest, external 3-fold, 20 Runs (=60 fitted models)
M1=mining(G3~.,rmath,model="randomForest",method=c("kfold",3,123),Runs=20) #cortez2008using
m=mmetric(M1,metric=c("MAE", "RMSE"))
print(m)
